1.研究背景及意义内容过于简单，对相关领域的研究及问题了解较浅。
2.研究的主要对象与目标在文章的背景与研究现状中不够明确，到底是离散智能
体离散动作控制决策研究还是针对ACER算法的研究。如果遵循论文题目，就应有相应
的章节对智能体离散动作控制决策的现有问题进行分析，并在算法设计部分进行针对
性的解决，以及效果验证，文中缺乏相应的介绍。
3.文献调研量较少，对相关领域的发展动态分析稍微欠缺。
4.论文中改进的A2CPER与MACPER两种算法实现过程均只有文字描述，缺乏完整的
图片示意。
5.论文章节安排破坏算法设计到验证的完整性，需调整：每一个算法设计后需进
行相应的仿真实验并进行结果分析，而不是单独一章进行仿真实验和结果说明。
6.论文中存在部分语句病句及少字问题：如摘要第1句话：“强化学习及其深度
强化学习衍生技术，已成为智能体决策领域的重要方。”、摘要第1段倒数第2句话：
“基于自注意力机制和？？？”以及第3段第1句话、第1章1.1小节第2段话等等，建
议仔细检查全文。
7.论文中图片问题较大：1）图1-1是2-2小节强化学习和深度强化学习的关系，
但是图片中却出现了元学习的关系，该小节并未介绍元学习。2）图2-3、图3-1图片
不清晰，建议自己画。3）图2-4中“交互”二字与其它地方不一致。4）流程图3-2中
字体大小不统一且流程图出现交叉的情况。5）图5-4至图5-6均为一个命名，实验数
据代表的是什么数据？
8.论文中的两个算法伪代码表均存在end for, end if丢失问题。
9.论文中存在部分格式问题，如第10页第1句话中Q(s,a1;θ)Q(s,a2;θ)之间缺
少逗号。
10.文献[33]期刊论文缺少卷号、页码；文献[37]出现中文句号；文献[34]、[4
1]多个作者最后一位与等之间缺少逗号。
实验部分：
1.论文表5-1 CartPole-v1（小车倒立摆）的状态空间设定中，设定值缺乏单位或者
解释。
2.论文表5-8 MountainCar-v0环境，对于动作空间的定义应该为向左加速，保持不动
，或者向右加速。如果只定义加速，不加速，则没有方向。
3.论文5.2.2小节对于所有的环境超参数的设置一致，不同环境解决的任务不同，环
境、状态、动作等设置都不同，超参数设置应该有异才对。且文中的逻辑混论，一开
始说由测试给出，最后一句说其为常用参数。并且没有给出附录。
4.图5-8的实验图描述应该放在对图5-8的实验分析之前。
5.对于MountainCar-v0 实验，没有给出奖励值曲线，用时间步长曲线代替分析并不
能说明其收敛。

（1）论文提出在大规模状态空间和复杂环境下，强化学习算法面临学习效率低下，
收敛过程不稳定等问题，但在第5章，对A2CPER 算法和 MACPER 算法验证实验，采用
的 Cartpole-v1，Acrobot-v1与MiniWorld 仿真环境，状态空间和动作空间较为简单
，维数较低，建议采用更复杂的仿真环境和控制任务，如MuJoCo，Pybullet等。
（2）国内外研究现状部分，对深度强化学习研究现状调研不足，没有对深度强化学
习算法最新进展进行总结。
（3）论文第3章和第4章，对于A2CPER 算法和MACPER 算法整体描述较为模糊，在第
三章中，论文对自注意力机制的论述模糊，不清楚其如何处理历史信息，自注意力机
制的输入是哪些信息，输出又送到哪个模块？
（4）图3-2内容疑似训练流程，不是算法流程
（5）第5章中的迷宫实验是较为简单的单任务，无法验证元学习对AC算法的改进
（6）部分参考文献的书写格式不够规范和完整，如文献[43]、[7]没有标注页码，文
献[44]格式不是会议文献格式，文献[14]中出现“Application Research of Compu
ters/Jisuanji Yingyong Yanjiu”，疑似期刊名称混入作者姓名